<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>Practical-machine-learning by mpmartins1970</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">Practical-machine-learning</h1>
      <h2 class="project-tagline">Prediction Assignment Writeup</h2>
      <a href="https://github.com/mpmartins1970/practical-machine-learning" class="btn">View on GitHub</a>
      <a href="https://github.com/mpmartins1970/practical-machine-learning/zipball/master" class="btn">Download .zip</a>
      <a href="https://github.com/mpmartins1970/practical-machine-learning/tarball/master" class="btn">Download .tar.gz</a>
    </section>

    <section class="main-content">
      <p>&lt;!DOCTYPE html&gt;</p>

<p></p>

<p></p>

<p>

</p>

<p></p>

<p></p>Prediction Assignment Writeup



<p>
</p>







code{white-space: pre;}

<p></p>




  pre:not([class]) {
    background-color: white;
  }





h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}


<p></p>

<p></p>


.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}


<div>












<div id="header">



<h1>
<a id="prediction-assignment-writeup" class="anchor" href="#prediction-assignment-writeup" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Prediction Assignment Writeup</h1>
<h4>
<a id="mpmartins1970" class="anchor" href="#mpmartins1970" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><em>mpmartins1970</em>
</h4>
<h4>
<a id="20160812" class="anchor" href="#20160812" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><em>2016/08/12</em>
</h4>

</div>

<hr>

<div id="executive-summary">
<h2>
<a id="executive-summary" class="anchor" href="#executive-summary" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Executive Summary</h2>
<p>In this report, data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants are used to quantify how well they did each particular activity. The goal of this report is to predict the manner in which they did the exercise, describing how the model was built, the expected out of sample error and why the choices were made. The predict model is used to predict 20 different test cases. Using exploratory data analysis and machine learning theory, the findings showed that Random Forest has the best accuracy for this testing dataset.</p>
</div>

<div id="exploratory-data-analysis">
<h2>
<a id="exploratory-data-analysis" class="anchor" href="#exploratory-data-analysis" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Exploratory Data Analysis</h2>
<p>Loading the training and test datasets that previously have been downloaded to working directory in local machine. The datasets have 160 variables.</p>
<pre><code># Libraries
library(caret)</code></pre>
<pre><code>## Loading required package: lattice</code></pre>
<pre><code>## Loading required package: ggplot2</code></pre>
<pre><code># Load the training and testing dataset
trainingDS &lt;- read.csv("./pml-training.csv", na.strings = c("NA","#DIV/0!"))
testingDS &lt;- read.csv("./pml-testing.csv", na.strings = c("NA","#DIV/0!"))</code></pre>
<p>Removing all the variables containing NA values, the near zero variance (NVZ) variables and id/timestamp variables.</p>
<pre><code># Cleaning data
trainingDS &lt;- trainingDS[,colSums(is.na(trainingDS)) == 0]
trainingDS &lt;- trainingDS[,-nearZeroVar(trainingDS)]
trainingDS &lt;- trainingDS[,-c(1:7)]</code></pre>
<p>Splitting data into a 70% training data set and a 30% testing data set to estimate the out of sample error of the predictor.</p>
<pre><code># Splitting data
inTrain &lt;- createDataPartition(y = trainingDS$classe, p = 0.70,list = F)
training &lt;- trainingDS[inTrain,] 
testing &lt;- trainingDS[-inTrain,] </code></pre>
</div>

<div id="prediction-model-building">
<h2>
<a id="prediction-model-building" class="anchor" href="#prediction-model-building" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Prediction Model Building</h2>
<p>The problem to be resolved is a classification one, so, using random forest, the out of sample error should be small. Random forest is used for the training dataset using cross-validation.</p>
<pre><code># Making report reproducible
set.seed(1970)

# Fitting Random Forest model
trc5 &lt;- trainControl(method = "cv", number = 5, allowParallel = TRUE, verbose = TRUE)
modelRF &lt;- train(classe~.,data = training, method = "rf", trControl = trc5, verbose = FALSE)</code></pre>
<pre><code>## Loading required package: randomForest</code></pre>
<pre><code>## randomForest 4.6-12</code></pre>
<pre><code>## Type rfNews() to see new features/changes/bug fixes.</code></pre>
<pre><code>## 
## Attaching package: 'randomForest'</code></pre>
<pre><code>## The following object is masked from 'package:ggplot2':
## 
##     margin</code></pre>
<pre><code>## + Fold1: mtry= 2 
## - Fold1: mtry= 2 
## + Fold1: mtry=26 
## - Fold1: mtry=26 
## + Fold1: mtry=51 
## - Fold1: mtry=51 
## + Fold2: mtry= 2 
## - Fold2: mtry= 2 
## + Fold2: mtry=26 
## - Fold2: mtry=26 
## + Fold2: mtry=51 
## - Fold2: mtry=51 
## + Fold3: mtry= 2 
## - Fold3: mtry= 2 
## + Fold3: mtry=26 
## - Fold3: mtry=26 
## + Fold3: mtry=51 
## - Fold3: mtry=51 
## + Fold4: mtry= 2 
## - Fold4: mtry= 2 
## + Fold4: mtry=26 
## - Fold4: mtry=26 
## + Fold4: mtry=51 
## - Fold4: mtry=51 
## + Fold5: mtry= 2 
## - Fold5: mtry= 2 
## + Fold5: mtry=26 
## - Fold5: mtry=26 
## + Fold5: mtry=51 
## - Fold5: mtry=51 
## Aggregating results
## Selecting tuning parameters
## Fitting mtry = 2 on full training set</code></pre>
<pre><code>modelRF$finalModel</code></pre>
<pre><code>## 
## Call:
##  randomForest(x = x, y = y, mtry = param$mtry, verbose = FALSE) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 2
## 
##         OOB estimate of  error rate: 0.74%
## Confusion matrix:
##      A    B    C    D    E  class.error
## A 3903    1    1    0    1 0.0007680492
## B   14 2631   13    0    0 0.0101580135
## C    1   16 2377    2    0 0.0079298831
## D    0    0   47 2204    1 0.0213143872
## E    0    0    1    4 2520 0.0019801980</code></pre>
<p>In sequence, the fitted model generated is examined with the testing sample from the partitioned training dataset to evaluate the accuracy and estimated error of prediction.</p>
<pre><code># Predicting with the Random Forest Model
predictionRF &lt;- predict(modelRF, testing)
confMatrixRF &lt;- confusionMatrix(predictionRF, testing$classe)
confMatrixRF</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1674   10    0    0    0
##          B    0 1126    3    0    0
##          C    0    3 1022   18    0
##          D    0    0    1  942    2
##          E    0    0    0    4 1080
## 
## Overall Statistics
##                                          
##                Accuracy : 0.993          
##                  95% CI : (0.9906, 0.995)
##     No Information Rate : 0.2845         
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16      
##                                          
##                   Kappa : 0.9912         
##  Mcnemar's Test P-Value : NA             
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            1.0000   0.9886   0.9961   0.9772   0.9982
## Specificity            0.9976   0.9994   0.9957   0.9994   0.9992
## Pos Pred Value         0.9941   0.9973   0.9799   0.9968   0.9963
## Neg Pred Value         1.0000   0.9973   0.9992   0.9955   0.9996
## Prevalence             0.2845   0.1935   0.1743   0.1638   0.1839
## Detection Rate         0.2845   0.1913   0.1737   0.1601   0.1835
## Detection Prevalence   0.2862   0.1918   0.1772   0.1606   0.1842
## Balanced Accuracy      0.9988   0.9940   0.9959   0.9883   0.9987</code></pre>
<p>The accuracy of the modeling method above is 99,4% with a small out of sample error. As a consequence, it could be expected almost all of the submitted test cases will be correct.</p>
</div>

<div id="predicting-with-the-testing-data">
<h2>
<a id="predicting-with-the-testing-data" class="anchor" href="#predicting-with-the-testing-data" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Predicting with the Testing Data</h2>
<p>Applying the Random Forest model to predict the 20 test cases provided (testing dataset) as shown below.</p>
<pre><code># Predicting using pml-testing.csv data
predictTestingDS &lt;- predict(modelRF, newdata = testingDS)
predictTestingDS</code></pre>
<pre><code>##  [1] B A B A A E D B A A B C B A E E A B B B
## Levels: A B C D E</code></pre>
</div>

<div id="conclusions">
<h2>
<a id="conclusions" class="anchor" href="#conclusions" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Conclusions</h2>
<p>From these data, after validation in the prediction quizz, the goal was accomplished since all the submitted test cases were correct.</p>
<hr>
</div>

<p></p>
</div>







<p>
</p>

      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/mpmartins1970/practical-machine-learning">Practical-machine-learning</a> is maintained by <a href="https://github.com/mpmartins1970">mpmartins1970</a>.</span>

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>

  
  </body>
</html>
